"""
Torch dataset object for synthetically rendered spatial data.
"""
'''
This code was generated by @Sidharth, This code contains the creation of dataset on fly

Input : dataset_dir, sr, split
Output : inputs #(1, 3, fs*T), target_audio #(1,1,fs*T)

'''
import torch.nn.functional as F
import os, glob
from pathlib import Path
import random
import scipy.ndimage
from torch.utils.data import Dataset
import pandas as pd
import torch
import torchaudio
from multiprocessing import Pool
# from src.datasets.augmentations.audio_augmentations import AudioAugmentations
import numpy as np
import subprocess
from datasets.gpuRIRsimulateRIR import PRASimulator
# from scipy.signal import fftconvolve
import pdb
import soundfile as sf
'''
LibriTTS
dir : /scr/LibriTTS
relevant folders : dev-clean, test-clean, train-clean-360
'''



#untar the libritts files to the /scr folder
# sh_path = '/mmfs1/gscratch/intelligentsystems/sidharth/codebase/shcodes/tar_libritts.sh'
# if os.path.exists('/scr/LibriTTS')==False:
#     subprocess.run(["sh", sh_path]) #creating libriTTS train, test and dev

class LibriTTS_spatial_audio(Dataset):
    def __init__(self, dataset_dir, sr, split, augmentations = [], samples_per_epoch=20000) -> None:
        super().__init__()
        assert split in ['train', 'val','test'], \
            "`split` must be one of ['train', 'val', 'test']"

        self.dataset_dir = Path(dataset_dir) #/scr/LibriTTS
        self.split = split #/train or valid or test
        self.sr = sr
        self.duration = 8
        mean = np.loadtxt("/mmfs1/gscratch/intelligentsystems/sidharth/codebase/ml_pipeline/spatial_audio_expt/src/datasets/mean.txt")
        std = np.loadtxt("/mmfs1/gscratch/intelligentsystems/sidharth/codebase/ml_pipeline/spatial_audio_expt/src/datasets/std.txt")
        self.mean = torch.tensor(mean)
        self.std = torch.tensor(std)
        # Data augmentation
        # self.perturbations = AudioAugmentations(augmentations)
        self.samples = sorted(list(self.dataset_dir.glob('**/*.wav')))
        # self.samples = sorted(list(Path(self.dataset_dir).glob('[0-9]*')))
        if self.split == 'train':
            self.samples_per_epoch = samples_per_epoch
        elif self.split =='val':
            self.samples_per_epoch = 2000
        else:
            self.samples_per_epoch =200

    def __len__(self):
        return self.samples_per_epoch

    def __getitem__(self, idx):
        '''
        Task : Get the source data from the libritts, generate RIR by calling gpuRIRsimulateRIR.py,
        store the resulting array in inputs and the target in outputs.
        
        '''
        audio_path = self.samples[idx] #(nb_rcv, T)
        audio, sr = torchaudio.load(audio_path)
        # normalized_audio = (audio - self.mean)/self.std




        fixed_target = 3
        target_audio = audio[fixed_target , :].clone()  #gt
        audio[fixed_target,:] *= 0

        #clip to only 6 seconds of audio 
        audio = audio[:, :16000*6]
        target_audio = target_audio[:16000*6]
        return audio, target_audio